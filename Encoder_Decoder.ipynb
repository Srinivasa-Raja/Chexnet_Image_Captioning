{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Encoder_Decoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpQqwK_D9EUI"
      },
      "source": [
        "<h2> Importing required libraries </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYqoEABX1EqW"
      },
      "source": [
        "import gdown\n",
        "import tarfile\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import xml.dom.minidom\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import regex as re\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from PIL import Image  \n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.backend import expand_dims\n",
        "from tensorflow import concat\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "tf.keras.backend.clear_session()\n",
        "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM,Layer,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import repeat\n",
        "from sklearn.utils import shuffle\n",
        "import nltk.translate.bleu_score as bleu"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCKk0yxZuwsK"
      },
      "source": [
        "#https://drive.google.com/file/d/12fbWv4WrpCJipa1_S-E7RK9Dw83Wu8GB/view?usp=sharing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "Gs4buDuru_Bp",
        "outputId": "04645b9f-3fbb-4a47-b051-222d7bdedf49"
      },
      "source": [
        "url = 'https://drive.google.com/uc?id=1U7D9lnjH-0CaXzhmua2rMtmdgS4DEH2k'\n",
        "output = 'proccessed.pkl'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1U7D9lnjH-0CaXzhmua2rMtmdgS4DEH2k\n",
            "To: /content/proccessed.pkl\n",
            "58.1MB [00:00, 74.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'proccessed.pkl'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PpNP3NG1P5e"
      },
      "source": [
        "data = pd.read_pickle('/content/proccessed.pkl')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "p5TRN38o2cFw",
        "outputId": "38cf2c09-a164-40f2-a609-41753b996c59"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>image1</th>\n",
              "      <th>image2</th>\n",
              "      <th>findings</th>\n",
              "      <th>image_features</th>\n",
              "      <th>findings_total</th>\n",
              "      <th>dec_ip</th>\n",
              "      <th>dec_op</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CXR3556</td>\n",
              "      <td>/content/png/CXR3556_IM-1741-1001-0001.png</td>\n",
              "      <td>/content/png/CXR3556_IM-1741-1001-0002.png</td>\n",
              "      <td>the lungs are clear. there is no pleural effus...</td>\n",
              "      <td>[[0.00041582860285416245, 0.001570420921780169...</td>\n",
              "      <td>&lt;start&gt; the lungs are clear. there is no pleur...</td>\n",
              "      <td>&lt;start&gt; the lungs are clear. there is no pleur...</td>\n",
              "      <td>the lungs are clear. there is no pleural effus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CXR32</td>\n",
              "      <td>/content/png/CXR32_IM-1511-1001.png</td>\n",
              "      <td>/content/png/CXR32_IM-1511-4001.png</td>\n",
              "      <td>the heart is normal in size. the mediastinum i...</td>\n",
              "      <td>[[0.0005354544264264405, 0.0019668142776936293...</td>\n",
              "      <td>&lt;start&gt; the heart is normal in size. the media...</td>\n",
              "      <td>&lt;start&gt; the heart is normal in size. the media...</td>\n",
              "      <td>the heart is normal in size. the mediastinum i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CXR260</td>\n",
              "      <td>/content/png/CXR260_IM-1090-1001.png</td>\n",
              "      <td>/content/png/CXR260_IM-1090-2001.png</td>\n",
              "      <td>lungs are clear bilaterally. cardiac and media...</td>\n",
              "      <td>[[0.0002745636156760156, 0.0018877924885600805...</td>\n",
              "      <td>&lt;start&gt; lungs are clear bilaterally. cardiac a...</td>\n",
              "      <td>&lt;start&gt; lungs are clear bilaterally. cardiac a...</td>\n",
              "      <td>lungs are clear bilaterally. cardiac and media...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CXR1301</td>\n",
              "      <td>/content/png/CXR1301_IM-0198-1001.png</td>\n",
              "      <td>/content/png/CXR1301_IM-0198-2001.png</td>\n",
              "      <td>heart size within normal limits, stable medias...</td>\n",
              "      <td>[[0.0005874697235412896, 0.0018448150949552655...</td>\n",
              "      <td>&lt;start&gt; heart size within normal limits, stabl...</td>\n",
              "      <td>&lt;start&gt; heart size within normal limits, stabl...</td>\n",
              "      <td>heart size within normal limits, stable medias...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CXR1921</td>\n",
              "      <td>/content/png/CXR1921_IM-0598-1001.png</td>\n",
              "      <td>/content/png/CXR1921_IM-0598-2001.png</td>\n",
              "      <td>redemonstration of moderately-inflated lungs, ...</td>\n",
              "      <td>[[0.00029747304506599903, 0.0014215346891433, ...</td>\n",
              "      <td>&lt;start&gt; redemonstration of moderately-inflated...</td>\n",
              "      <td>&lt;start&gt; redemonstration of moderately-inflated...</td>\n",
              "      <td>redemonstration of moderately-inflated lungs, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  patient_id  ...                                             dec_op\n",
              "0    CXR3556  ...  the lungs are clear. there is no pleural effus...\n",
              "2      CXR32  ...  the heart is normal in size. the mediastinum i...\n",
              "4     CXR260  ...  lungs are clear bilaterally. cardiac and media...\n",
              "5    CXR1301  ...  heart size within normal limits, stable medias...\n",
              "6    CXR1921  ...  redemonstration of moderately-inflated lungs, ...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSCzuoeg_jNU"
      },
      "source": [
        "<h2> Test train split </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOEA4UPxFmNs"
      },
      "source": [
        "#Test and train split\n",
        "X_train, X_test = train_test_split(data.values , test_size = 0.2 )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn_U8i2PQFTB",
        "outputId": "12767561-1431-4586-d2ab-3543003ca2cc"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2669, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufAfO1FQQIBQ",
        "outputId": "6dea8df8-c4a3-44e7-b09a-c81c7b4b78d6"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(668, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD_DXMKRgs_C"
      },
      "source": [
        "X_train = X_train[:-19, :]\n",
        "X_test = X_test[:-18, :]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp5eEUK0Mc4P"
      },
      "source": [
        "<h2> Tokenization </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IusPikKFsER"
      },
      "source": [
        "\n",
        "t1 = Tokenizer( filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n',oov_token='OOV')\n",
        "t1.fit_on_texts(X_train[:,5])\n",
        "\n",
        "t1.word_index['<pad>'] = 0\n",
        "t1.index_word[0] = '<pad>'\n",
        "vocab_size_imp = len(t1.word_index) + 1\n",
        "\n",
        "dec_inp = t1.texts_to_sequences(X_train[:,6])\n",
        "\n",
        "dec_inp = pad_sequences(dec_inp, maxlen=98, padding='post') \n",
        "\n",
        "dec_inp_cv = t1.texts_to_sequences(X_test[:,6])\n",
        "\n",
        "dec_inp_cv = pad_sequences(dec_inp_cv, maxlen=98, padding='post') \n",
        " \n",
        "dec_op = t1.texts_to_sequences(X_train[:,7])\n",
        "\n",
        "dec_op = pad_sequences(dec_op, maxlen=98, padding='post') \n",
        "\n",
        "dec_op_cv = t1.texts_to_sequences(X_test[:,7])\n",
        "\n",
        "dec_op_cv = pad_sequences(dec_op_cv, maxlen=98, padding='post') "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3SxzS22U1k-",
        "outputId": "53c07409-7aa5-49b3-deab-2660b9df6ac5"
      },
      "source": [
        "vocab_size_imp"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTHh6YoHBbYX"
      },
      "source": [
        "imp1 = {}\n",
        "imp2 = {}\n",
        "for key,value in t1.word_index.items():\n",
        "  imp1[value] = key\n",
        "  imp2[key] = value"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eLJNNmX9Sa5"
      },
      "source": [
        "<h2> Encoder </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vWPvXhy4Ms9"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.dense1 = Dense(512)\n",
        "        self.d1 = Dropout(0.5)\n",
        "\n",
        "\n",
        "    def call(self,image_data):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        self.image_data = image_data\n",
        "        self.enc_out = self.dense1(self.image_data)\n",
        "        self.enc_out =self.d1(self.enc_out )\n",
        "\n",
        "        \n",
        "        return self.enc_out\n",
        "    \n",
        "\n",
        "      \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9g8stOz9jC0"
      },
      "source": [
        "<h2> Decoder </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LhjPngi6PkJ"
      },
      "source": [
        "class Decoder(Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Decoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size = lstm_size\n",
        "        self.d2  = Dropout(0.3)\n",
        "        self.dec_emb = Embedding(out_vocab_size,300,trainable = True)            #(None , 12,embedding_size)\n",
        "        self.dec_lstm = LSTM(self.lstm_size, return_sequences=True, name=\"Decoder_LSTM\")  #(None , 12,lstm_size)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "    def call(self,input_sequence):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "        \n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        #print(\"DECODER ==> INPUT SQUENCES SHAPE :\",target_sentances.shape)\n",
        "        self.input_sequence = input_sequence\n",
        "        \n",
        "        self.target_embedd           = self.dec_emb (self.input_sequence)\n",
        "        self.target_embedd =self.d2(self.target_embedd )\n",
        "        #print(\"WE ARE INITIALIZING DECODER WITH ENCODER STATES :\",state_h.shape, state_c.shape)\n",
        "        lstm_output      = self.dec_lstm(self.target_embedd)\n",
        "\n",
        "        return lstm_output  \n",
        "\n",
        "\n",
        "\n",
        "      \n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYwVzjYk9mh1"
      },
      "source": [
        "<h2> Encoder - Decoder </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saHPVLfG7Wzk"
      },
      "source": [
        "class Encoder_decoder(Model):\n",
        "    \n",
        "    #def __init__(self,*params):\n",
        "    def __init__(self,out_vocab_size,embedding_size_d,lstm_size_d,input_length_d,batch_size):\n",
        "        \n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_size_d = embedding_size_d\n",
        "        self.lstm_size_d = lstm_size_d\n",
        "        self.input_length_d = input_length_d\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.encoder = Encoder()\n",
        "        \n",
        "        self.decoder = Decoder(out_vocab_size , embedding_size_d, lstm_size_d,input_length_d )\n",
        "        self.dense   = TimeDistributed(Dense(self.out_vocab_size, activation='softmax'))\n",
        "        self.d3 = Dropout(0.3)\n",
        "    \n",
        "    \n",
        "    #def call(self,*params):\n",
        "    def call(self,data):\n",
        "    \n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        self.input1,self.input2 = data[0], data[1]\n",
        "        print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
        "        self.encoder_output = self.encoder(self.input1)\n",
        "        print(\"-\"*27)\n",
        "        #print(\"ENCODER ==> OUTPUT SHAPE\",self.encoder_output.shape)\n",
        "        #print(\"ENCODER ==> HIDDEN STATE SHAPE\",self.encoder_h.shape)\n",
        "        #print(\"ENCODER ==> CELL STATE SHAPE\", self.encoder_c.shape)\n",
        "        print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
        "        self.decoder_output  = self.decoder(self.input2)\n",
        "        #self.decoder_output =Dropout(0.3)(self.decoder_output)\n",
        "        self.add=tf.keras.layers.Add()([self.encoder_output, self.decoder_output])\n",
        "        self.add =self.d3(self.add)\n",
        "        \n",
        "        output         = self.dense(self.add)\n",
        "        print(\"-\"*27)\n",
        "        print(\"FINAL OUTPUT SHAPE\",output.shape)\n",
        "        print(\"=\"*50)\n",
        "        return output\n",
        "\n",
        "\n",
        "        \n",
        "        "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UyYFADO65nQ"
      },
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "model1 = Encoder_decoder(vocab_size_imp,300,512,36,50)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgyi9_Tz7L6I"
      },
      "source": [
        "<h2> Call Backs <h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU6gd6KD7edx"
      },
      "source": [
        "!mkdir checkpoint"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "godsG7byYChE"
      },
      "source": [
        "cwd = os.getcwd()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLdpK-LY7xdK"
      },
      "source": [
        "checkpoint_filepath = cwd + '/' + 'checkpoint' + '/'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5mAA22CP791V",
        "outputId": "3629138c-b5b4-4465-828d-6574cfef58ae"
      },
      "source": [
        "checkpoint_filepath"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/checkpoint/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI8JI42-9EIj"
      },
      "source": [
        "<h3> Check point <h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzuSe2oQ7Kb8"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    verbose = 1,\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJHp7CRWB2HZ"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTU4RTtv9JCM"
      },
      "source": [
        "<h3> LR optimizer <h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Jhbtt78zyC"
      },
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8,mode = 'min',verbose = 1,\n",
        "                              patience=1, min_lr=0.0001)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6kD3Z2Q87tG"
      },
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model1.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRtO-w6fCW9B"
      },
      "source": [
        "train_inp = np.vstack(X_train[:,4]).astype(np.float)\n",
        "test_inp = np.vstack(X_test[:,4]).astype(np.float)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEg2lXqf8-Qc",
        "outputId": "ba998e50-e923-4cf7-8c0d-dd8a356f18e2"
      },
      "source": [
        "\n",
        "model1.fit([train_inp,dec_inp ],dec_op ,validation_data= ([test_inp, dec_inp_cv],dec_op_cv),batch_size= 25,epochs  = 30,callbacks=[reduce_lr,model_checkpoint_callback])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "==================== ENCODER ====================\n",
            "---------------------------\n",
            "==================== DECODER ====================\n",
            "---------------------------\n",
            "FINAL OUTPUT SHAPE (25, 98, 1806)\n",
            "==================================================\n",
            "==================== ENCODER ====================\n",
            "---------------------------\n",
            "==================== DECODER ====================\n",
            "---------------------------\n",
            "FINAL OUTPUT SHAPE (25, 98, 1806)\n",
            "==================================================\n",
            "105/106 [============================>.] - ETA: 0s - loss: 2.6907==================== ENCODER ====================\n",
            "---------------------------\n",
            "==================== DECODER ====================\n",
            "---------------------------\n",
            "FINAL OUTPUT SHAPE (25, 98, 1806)\n",
            "==================================================\n",
            "106/106 [==============================] - 37s 35ms/step - loss: 2.6777 - val_loss: 1.6630\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.66296, saving model to /content/checkpoint/\n",
            "Epoch 2/30\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 1.6012 - val_loss: 1.3764\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.66296 to 1.37645, saving model to /content/checkpoint/\n",
            "Epoch 3/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.2547 - val_loss: 1.0573\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.37645 to 1.05732, saving model to /content/checkpoint/\n",
            "Epoch 4/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.9568 - val_loss: 0.9034\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.05732 to 0.90342, saving model to /content/checkpoint/\n",
            "Epoch 5/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.8151 - val_loss: 0.8123\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.90342 to 0.81228, saving model to /content/checkpoint/\n",
            "Epoch 6/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.7355 - val_loss: 0.7657\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.81228 to 0.76572, saving model to /content/checkpoint/\n",
            "Epoch 7/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.6728 - val_loss: 0.7290\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.76572 to 0.72900, saving model to /content/checkpoint/\n",
            "Epoch 8/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.6160 - val_loss: 0.7049\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.72900 to 0.70487, saving model to /content/checkpoint/\n",
            "Epoch 9/30\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5827 - val_loss: 0.6856\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.70487 to 0.68563, saving model to /content/checkpoint/\n",
            "Epoch 10/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5445 - val_loss: 0.6709\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.68563 to 0.67089, saving model to /content/checkpoint/\n",
            "Epoch 11/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5056 - val_loss: 0.6655\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.67089 to 0.66547, saving model to /content/checkpoint/\n",
            "Epoch 12/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4887 - val_loss: 0.6525\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.66547 to 0.65249, saving model to /content/checkpoint/\n",
            "Epoch 13/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4707 - val_loss: 0.6509\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.65249 to 0.65094, saving model to /content/checkpoint/\n",
            "Epoch 14/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4370 - val_loss: 0.6523\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.65094\n",
            "Epoch 15/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4117 - val_loss: 0.6412\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.65094 to 0.64119, saving model to /content/checkpoint/\n",
            "Epoch 16/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3975 - val_loss: 0.6422\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.64119\n",
            "Epoch 17/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3808 - val_loss: 0.6396\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.64119 to 0.63962, saving model to /content/checkpoint/\n",
            "Epoch 18/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3660 - val_loss: 0.6388\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.63962 to 0.63882, saving model to /content/checkpoint/\n",
            "Epoch 19/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3439 - val_loss: 0.6376\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.63882 to 0.63755, saving model to /content/checkpoint/\n",
            "Epoch 20/30\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3381 - val_loss: 0.6388\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.63755\n",
            "Epoch 21/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3305 - val_loss: 0.6376\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.63755\n",
            "Epoch 22/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3146 - val_loss: 0.6344\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.63755 to 0.63436, saving model to /content/checkpoint/\n",
            "Epoch 23/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.2959 - val_loss: 0.6351\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.63436\n",
            "Epoch 24/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.2797 - val_loss: 0.6410\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.63436\n",
            "Epoch 25/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.2867 - val_loss: 0.6387\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.63436\n",
            "Epoch 26/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.2768 - val_loss: 0.6376\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.63436\n",
            "Epoch 27/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.2705 - val_loss: 0.6365\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.63436\n",
            "Epoch 28/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.2634 - val_loss: 0.6388\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.63436\n",
            "Epoch 29/30\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.2642 - val_loss: 0.6370\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.63436\n",
            "Epoch 30/30\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.2531 - val_loss: 0.6383\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.63436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0f309eb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmyvGP_J8B0W"
      },
      "source": [
        "def predict(input_model):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model1 predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model1.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  input_sentence = input_model\n",
        "  \n",
        "  encoder_output= model1.layers[0](input_sentence)#,self.initial_state) \n",
        "  encoder_output = model1.layers[0].d1(encoder_output)\n",
        "\n",
        "  cur_vec = np.ones((1, 1)) * imp2['<start>'] # Here replace with index of <start> in the english vocab\n",
        "  pred = []\n",
        "  predicted_senence = \"<start>\"\n",
        "  for i in range(20):\n",
        "    cur_emb = model1.layers[1].dec_emb(cur_vec)\n",
        "    cur_emb = model1.layers[1].d2(cur_emb)\n",
        "    infe_output= model1.layers[1].dec_lstm(cur_emb)\n",
        "    infe_output=tf.keras.layers.Add()([encoder_output, infe_output])\n",
        "    infe_output=model1.layers[2](infe_output)\n",
        "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
        "    pred.append(cur_vec[0][0])\n",
        "\n",
        "    predicted_senence = predicted_senence + ' ' + imp1[cur_vec[0][0]+1]\n",
        "    if(cur_vec[0][0] == imp2['<end>'] ):\n",
        "      break\n",
        "  return predicted_senence.strip()\n",
        "\n",
        "#max_length = int(padlength)\n",
        "#max_length\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRiBnx6fOHdV"
      },
      "source": [
        "<h2> Inference <h2>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7R3-ro_CSnC",
        "outputId": "8806d0c3-e69d-4277-9057-2da2bc9b598a"
      },
      "source": [
        "num = 36\n",
        "im_o = np.vstack(X_test[:,4][num]).astype(np.float)\n",
        "tex_o = X_test[:,5][num]\n",
        "print(\"Original Sentence is : \",tex_o)\n",
        "print(\"Predicted sentence: \",predict(im_o))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence is :  <start> the heart is normal in size. the mediastinum is stable. rectal balloon is noted. lungs are mildly hypoinflated. there is again eventration of the hemidiaphragms/ bochdalek hernia, posteriorly as seen on the lateral projection. bilateral pleural thickening is noted. there are streaky opacities in the lung bases unchanged, chronic atelectasis. <end>\n",
            "Predicted sentence:  <start> no airspace are anterior heart are anterior heart are anterior heart are anterior heart are anterior heart are anterior heart\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6OG6YlOqJqQ",
        "outputId": "1570e724-7802-47a9-f08b-32502393c294"
      },
      "source": [
        "num = 98\n",
        "im_o = np.vstack(X_test[:,4][num]).astype(np.float)\n",
        "tex_o = X_test[:,5][num]\n",
        "print(\"Original Sentence is : \",tex_o)\n",
        "print(\"Predicted sentence: \",predict(im_o))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence is :  <start> the cardiomediastinal silhouette and pulmonary vasculature are within normal limits in size. the lungs are clear of focal airspace disease, pneumothora, or pleural effusion. there are no acute bony findings. <end>\n",
            "Predicted sentence:  <start> no left airspace are there left airspace are there left airspace are there left airspace are there left airspace are\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATAak3WSO8O5",
        "outputId": "b150b427-57eb-4b3c-ad92-2469441b4e0b"
      },
      "source": [
        "num = 65\n",
        "im_o = np.vstack(X_test[:,4][num]).astype(np.float)\n",
        "tex_o = X_test[:,5][num]\n",
        "print(\"Original Sentence is : \",tex_o)\n",
        "print(\"Predicted sentence: \",predict(im_o))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence is :  <start> there is mild blunting of the costophrenic . there is right basilar airspace disease. there is no pneumothora. the cardiac mediastinal silhouettes are normal. pulmonary are slightly prominent. calcified hilar lymph . no acute bony abnormalities. <end>\n",
            "Predicted sentence:  <start> no left airspace are there within pleural vasculature opacities are there within pleural vasculature opacities are there within pleural vasculature\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6tr-0a8Opjh"
      },
      "source": [
        "<h2> Bleu score <h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYWWk9qiEZuh",
        "outputId": "8aeb91a4-6d42-4ee2-dd8d-c8666315a45b"
      },
      "source": [
        "#https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
        "b = 0\n",
        "\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "  im_o = np.vstack(X_test[:,4][i]).astype(np.float)\n",
        "  pred = predict(im_o)\n",
        "  org= X_test[:,5][i]\n",
        "\n",
        "  b=  b + bleu.sentence_bleu([org.split()], pred.split() )\n",
        "\n",
        "print(\"Bleu score is : \",b/X_test.shape[0])\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu score is :  0.3737796011599721\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}